# Automotive Downtime Analytics

This project simulates and analyses unplanned downtime events in an automotive production plant.  
The goal is to show how a data analyst can work with shop-floor data (lines, stations, robots, failure codes, shifts) to build KPIs, visualisations and, later on, dashboards that support better operational decisions.

The dataset is synthetic but realistic and is inspired by real automotive environments (BodyShop, PaintShop, FinalAssembly, multiple robots, three shifts, etc.).

---

## 1. Dataset

The main dataset is stored in:

- `Data/downtime_events.csv`

Each row represents a single downtime event. The key fields are:

- `event_id` – unique identifier of the event  
- `timestamp_start`, `timestamp_end` – start and end time of the downtime  
- `line_id` – production line (e.g. BodyShop, PaintShop, FinalAssembly)  
- `station_id` – station within the line (e.g. BS_Weld_01, FA_Station_02, …)  
- `robot_id` – robot involved in the event (R001–R030)  
- `failure_code` – specific failure code (E01–E06)  
- `failure_category` – high-level failure type (mechanical, electrical, programming, sensor, material_supply, other)  
- `downtime_minutes` – duration of the event in minutes  
- `shift` – shift when the event started (morning, afternoon, night)  
- `pieces_lost` – approximate number of pieces lost due to the stop  
- `day_of_week` – day of the week of the event  

The dataset is generated by the script:

- `generate_downtime_events.py`

Using NumPy and Python’s random module, the script creates 8,000 events over a 6-month period, with realistic patterns such as more downtime at night and slightly longer stops in BodyShop.

---

## 2. Project structure

```
automotive-downtime-analytics/
├─ Data/
│  └─ downtime_events.csv
├─ notebooks/
│  ├─ 01_data_cleaning.ipynb
│  └─ 02_eda_kpis.ipynb
├─ generate_downtime_events.py
└─ README.md

01_data_cleaning.ipynb – loads the dataset, converts timestamps to proper datetime types, engineers time-based features (date, month, weekday) and checks data quality.

02_eda_kpis.ipynb – performs exploratory data analysis and computes key KPIs with visualisations.

---

## 3. Enviroment and how to run

Recommended Python version: 3.10+

Install dependencies

From inside the project folder:

python -m pip install pandas matplotlib


(Optional but useful: Jupyter / VS Code with the Jupyter extension.)

Run the analysis

Open notebooks/01_data_cleaning.ipynb

Run all cells to load and prepare the data.

Open notebooks/02_eda_kpis.ipynb

Run all cells to reproduce the analysis and charts.

Regenerate the dataset (optional)

If you want to regenerate the synthetic dataset from scratch:

python generate_downtime_events.py


This will create (or overwrite) a downtime_events.csv file in the project folder, which you can then move or keep under Data/.

---

## 4. Exploratory data analysis & KPIs

In 02_eda_kpis.ipynb the following KPIs and views are computed:

Total downtime (minutes) and average downtime per event

Downtime by production line (line_id)

Downtime by shift (shift)

Downtime by failure category (failure_category)

Top failure codes by total downtime (failure_code)

Monthly downtime trend based on the event start date

Example insights from the analysis (results will depend on the random seed):

BodyShop shows the highest total downtime in the 6-month period, clearly above PaintShop and FinalAssembly. This suggests that most improvement potential is concentrated in the body shop area.

The night shift concentrates the largest share of downtime, followed by the afternoon shift. This pattern may reflect lower staffing levels, less supervision or maintenance activities scheduled during the night.

Mechanical and electrical failures are responsible for the majority of downtime minutes. Focusing preventive maintenance and root-cause analysis on these categories would likely have the biggest impact on availability.

A small number of failure codes (e.g. E01 and E02) account for a disproportionate amount of downtime. Prioritising corrective actions for these critical codes could significantly reduce total downtime.

---

## 5. Possible extensions

Future extensions of this project could include:

Building an interactive dashboard (e.g. with Streamlit or Power BI) with filters by date, line and shift, and KPI cards (total downtime, average downtime/event, top failure code, etc.).

Creating a predictive model to estimate the probability of a downtime event in the next shift based on historical patterns.

Adding cost per minute of downtime to quantify the financial impact of different failure types, lines and shifts, and prioritise improvement actions by economic impact.

---

## 6. About the author

This project was created as part of a personal transition from industrial robotics and automotive production to data analytics.
It combines real-world shop-floor knowledge (lines, stations, robots, shifts, failure codes) with data analysis tools in Python to produce actionable insights for operations and maintenance teams.
